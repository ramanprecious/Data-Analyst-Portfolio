{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part II - (Explanatory data analysis of Prosper loan dataset)\n",
    "## by (Raman Precious)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## Investigation Overview\n",
    "\n",
    "\n",
    "> The overall goal of this presentation is share with people the importance of rebranding when a company is not doing so well, using the Prosper organization as a case study, as well as exa,mining the realtionship between Prosper Rating and Lender yield. The key insights reveal by the several analysis of the given dataset are:\n",
    "\n",
    "- There was a dip in 2009 that indicates a 'pause period' where the company rebranded itself and raised the bar of crediting goals and visions.\n",
    "\n",
    "- The number of defaulted loans pre-revolution of the company is higher than that of  post-revolution. This shows that the decision to revolutionize the company was a success. There is however a concerning observation of increased defaulted loan from 2012. This should be thoroughly checked.\n",
    "\n",
    "- High risk loans have a higher lender yield. This is profitable for lenders, as borrowers with poor credit rating will have higher APR which returns higher yields. Also, there are many defaulted loans in the high risk category, thereby proving that the prosper rating system for loan approval is somewhat accurate.\n",
    "\n",
    "\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "> I investigated the Prosper loan dataset provided by Prosper for insights and visualizations that would shed light on the progress of the company and their operations. This prosper data set contains 113,937 loans with 81 variables on each loan, including loan amount, borrowers' rate (or interest rate), current loan status, borrowers' income, and many others.\n",
    "\n",
    "Data dictionary for better understanding of the variables are in this link: https://docs.google.com/spreadsheets/d/1gDyi_L4UvIrLTEC6Wri5nbaMmkGmLQBk-Yx3z0XDEtI/edit#gid=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# suppress warnings from final output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'prosperLoanData.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fb325a03c3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloan_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prosperLoanData.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'prosperLoanData.csv' does not exist"
     ]
    }
   ],
   "source": [
    "loan_df = pd.read_csv('prosperLoanData.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> Note that the above cells have been set as \"Skip\"-type slides. That means\n",
    "that when the notebook is rendered as http slides, those cells won't show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def nullV() :  \n",
    "    y = loan_df.isnull().sum()\n",
    "    for i in range(len(y)) :\n",
    "        if y[i] != 0 :\n",
    "            x= y[i] \n",
    "            col = loan_df.columns[i]\n",
    "            z= (x/loan_df.shape[0])*100\n",
    "            print(str(i) + \" - \" + col + \" - \" + str(x) + \" nulls -\"+ str(round(z,2)) +\"%\")\n",
    "nullV()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "loan_df.drop(columns=[\"TotalProsperLoans\",\"TotalProsperPaymentsBilled\",\n",
    "                 \"ProsperPaymentsLessThanOneMonthLate\",\"ProsperPaymentsOneMonthPlusLate\",\"ProsperPrincipalBorrowed\",\n",
    "                \"ProsperPrincipalOutstanding\",\"ScorexChangeAtTimeOfListing\",\"LoanFirstDefaultedCycleNumber\",\"OnTimeProsperPayments\"],inplace= True )\n",
    "\n",
    "loan_df.drop(columns = ['ListingKey', 'ListingNumber', 'GroupKey', 'LoanKey', 'LoanNumber', 'MemberKey'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "borrower_fees = loan_df['BorrowerAPR'] - loan_df['BorrowerRate']\n",
    "fees_mean = borrower_fees.mean()\n",
    "loan_df['BorrowerAPR'].fillna((loan_df['BorrowerRate'] + fees_mean), inplace = True)\n",
    "\n",
    "\n",
    "DTIR = loan_df['DebtToIncomeRatio'].mean()\n",
    "loan_df['DebtToIncomeRatio'].fillna(DTIR, inplace = True)\n",
    "\n",
    "loan_df.dropna(subset=[ 'Occupation','BorrowerState','CurrentDelinquencies',\"CreditScoreRangeLower\", 'OpenCreditLines'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# convert columns from 'object' datatype to 'datetime'\n",
    "loan_df['ListingCreationDate'] = pd.to_datetime(loan_df['ListingCreationDate'])\n",
    "loan_df['LoanOriginationDate'] = pd.to_datetime(loan_df['LoanOriginationDate'])\n",
    "loan_df['ClosedDate'] = pd.to_datetime(loan_df['ClosedDate'])\n",
    "\n",
    "# split variables into day, month and year\n",
    "loan_df['ListingDay'] = loan_df['ListingCreationDate'].dt.day\n",
    "loan_df['ListingMonth'] = loan_df['ListingCreationDate'].dt.month_name()\n",
    "loan_df['ListingYear'] = loan_df['ListingCreationDate'].dt.year\n",
    "loan_df['OriginationDay'] = loan_df['LoanOriginationDate'].dt.day\n",
    "loan_df['OriginationMonth'] = loan_df['LoanOriginationDate'].dt.month_name()\n",
    "loan_df['OriginationYear'] = loan_df['LoanOriginationDate'].dt.year\n",
    "loan_df['ClosedDay'] = loan_df['ClosedDate'].dt.day\n",
    "loan_df['ClosedMonth'] = loan_df['ClosedDate'].dt.month_name()\n",
    "loan_df['ClosedYear'] = loan_df['ClosedDate'].dt.year\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "loan_df['ProsperRating (numeric)'].replace(to_replace = [0,1,2,3,4,5,6,7], value = ['N/A', 'HR', 'E', 'D', 'C','B', 'A', 'AA'], inplace = True)\n",
    "loan_df.rename(columns = {'ProsperRating (numeric)':'ProsperRating'}, inplace = True)\n",
    "\n",
    "loan_df['ListingCategory (numeric)'].replace(to_replace=[0,1,2,3,4,5,6,7,8, 9, 10,11,12,13,14,15,16,17,18,19,20],\n",
    "                                        value=['Not Available','Debt Consolidation','Home Improvement','Business','Personal Loan',\n",
    "                                               'Student Use','Auto','Other','Baby&Adoption','Boat','Cosmetic Procedure',\n",
    "                                               'Engagement Ring','Green Loans','Household Expenses','Large Purchases',\n",
    "                                               'Medical/Dental','Motorcycle,','RV','Taxes','Vacation','Wedding Loans'],inplace=True)\n",
    "loan_df.rename(columns = {'ListingCategory (numeric)':'ListingCategory'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_dict = {'ProsperRating': ['N/A','HR','E','D','C', 'B', 'A', 'AA']}\n",
    "for var in ordinal_dict:\n",
    "    ordered_var = pd.api.types.CategoricalDtype(ordered = True, categories = ordinal_dict[var])\n",
    "    loan_df[var] = loan_df[var].astype(ordered_var)\n",
    "    \n",
    "loan_df.drop(columns = ['ListingCreationDate','StatedMonthlyIncome','MonthlyLoanPayment','LoanOriginationDate', 'ClosedDate','AmountDelinquent', 'LoanMonthsSinceOrigination', 'LoanCurrentDaysDelinquent', 'FirstRecordedCreditLine', 'EstimatedEffectiveYield', 'EstimatedLoss',\n",
    "                       'EstimatedReturn', 'ProsperRating (Alpha)', 'CurrentlyInGroup', 'DateCreditPulled',\n",
    "                       'DelinquenciesLast7Years', 'PublicRecordsLast10Years', 'BankcardUtilization',\n",
    "                       'PublicRecordsLast12Months', 'ProsperScore', 'TotalTrades', 'TradesNeverDelinquent (percentage)',\n",
    "                       'TradesOpenedLast6Months', 'IncomeVerifiable', 'LP_CustomerPayments', 'LP_CustomerPrincipalPayments',\n",
    "                       'LP_InterestandFees', 'LP_ServiceFees', 'LP_CollectionFees', 'LP_GrossPrincipalLoss', 'LP_NetPrincipalLoss',\n",
    "                       'LP_NonPrincipalRecoverypayments', 'PercentFunded', 'Recommendations', 'InvestmentFromFriendsCount',\n",
    "                       'InvestmentFromFriendsAmount', 'RevolvingCreditBalance','Investors', 'EmploymentStatusDuration','OpenCreditLines',\n",
    "                       'OpenRevolvingAccounts','AvailableBankcardCredit','OpenRevolvingMonthlyPayment','TotalCreditLinespast7years', 'TotalInquiries',  'InquiriesLast6Months'], inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "loan_df['Occupation'] = loan_df['Occupation'].astype('category')\n",
    "loan_df['BorrowerState'] = loan_df['BorrowerState'].astype('category')\n",
    "loan_df['LoanStatus'] = loan_df['LoanStatus'].astype('category')\n",
    "loan_df['ListingCategory'] = loan_df['ListingCategory'].astype('category')\n",
    "loan_df['EmploymentStatus'] = loan_df['EmploymentStatus'].astype('category')\n",
    "\n",
    "\n",
    "loan_df['CreditScore'] = (loan_df['CreditScoreRangeUpper'] + loan_df['CreditScoreRangeLower'])/2\n",
    "loan_df.drop(columns =['CreditScoreRangeLower','CreditScoreRangeUpper'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "loan_df['LoanOriginationQuarter'] = loan_df['LoanOriginationQuarter'].str.split(' ').str[0]\n",
    "\n",
    "loan_df['LoanOriginationQuarter'] = loan_df['OriginationYear'].map(str) +  ' ' + loan_df['LoanOriginationQuarter'].map(str)\n",
    "\n",
    "loan_df[\"LoanStatus\"]= loan_df[\"LoanStatus\"].replace({\"FinalPaymentInProgress\": \"Current\", \"Past Due (1-15 days)\": \"Past Due\", 'Cancelled': 'Defaulted', 'Chargedoff' : 'Defaulted', 'Past Due (16-30 days)': 'Past Due', 'Past Due (31-60 days)': 'Past Due','Past Due (61-90 days)': 'Past Due', 'Past Due (91-120 days)': 'Past Due', 'Past Due (>120 days)': 'Past Due'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Visualization 1)\n",
    "\n",
    "> There was a dip in 2009 that indicates a 'pause period' where the company rebranded itself and raised the bar of crediting goals and visions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create a time series\n",
    "\n",
    "d = loan_df.groupby(['LoanOriginationQuarter','LoanStatus',]).size().unstack()\n",
    "plt.figure(figsize = [10, 8])\n",
    "d.plot(kind = 'bar', stacked = True, legend = True)\n",
    "plt.ylabel('counts')\n",
    "plt.title('Time series to show relationship between Quarter and Loan status group');\n",
    "\n",
    "{\n",
    "    \"tags\": [\n",
    "        \"to_remove\"\n",
    "    ],\n",
    "    \"slideshow\": {\n",
    "        \"slide_type\": \"Sub-Slide\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> This chart shows the performance of the loans since their commencement. It is revealed that a large number of the loans requested are either completed or current with a low level of defaulted and past due loans. It reveals the productivity trend of the company over the years. The company also began to issue lots of loan in recent times which signifies a high productivity. Some of the unusual distributions are the absence of the 2009 quarter one and non-productivity in quarter two. This is sure to be the cause of the dip in 2009 and indicates a 'pause period' where the company was  rebranded, stategies were inculcated, and the bar of high crediting goals and visions was raised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Visualization 2)\n",
    "\n",
    "> The number of defaulted loans pre-revolution of the company is higher than that of post-revolution. This shows that the decision to revolutionize the company was a success. There is however a concerning observation of increased defaulted loan from 2012. This should be thoroughly checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# create time series\n",
    "b = loan_df[loan_df['LoanStatus'] == 'Defaulted']\n",
    "\n",
    "bb = b['LoanOriginationQuarter'].value_counts().rename_axis('Quarters').reset_index(name='counts').sort_values('Quarters')\n",
    "figsize = [10,5]\n",
    "f, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "x_col= 'Quarters'\n",
    "y_col = 'counts'\n",
    "\n",
    "sb.pointplot(ax=ax, x=x_col,y=y_col,data=bb)\n",
    "\n",
    "plt.tick_params(axis='x', rotation=90)\n",
    "plt.title('Time series of defaulted loan per quarter');\n",
    "\n",
    "{\n",
    "    \"tags\": [\n",
    "        \"to_remove\"\n",
    "    ],\n",
    "    \"slideshow\": {\n",
    "        \"slide_type\": \"Sub-Slide\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> A drastic reduction in default payments is noticed between 2008 - 2009 as well as towards 2013. This plot was chosen because it is straightforward and delivers its message precisely. Prior to 2009, we can see that the rate generally hovered around 1000 to 1400 loans, which is significantly high and a clear area for improvement. Prosper stopped making new loans between the fourth quarter of 2008 and the third quarter of 2009. That explains the sharp drop during that time period. They maintained that low default rate throughout 2010, when they restarted their service with new policies. During 2011, it returned to around 30% and remained there until 2012. It is important to note that from 2011 onwards, there are still loans in operation, and we cannot draw conclusions based on the data. The decrease in 2013 is due to the fact that the majority of loans at the time are either current or in the final stages of repayment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Visualization 3)\n",
    "\n",
    "> High risk loans have a higher lender yield. This is profitable for lenders, as borrowers with poor credit rating will have higher APR which returns higher yields. Also, there are many defaulted loans in the high risk category, thereby proving that the prosper rating system for loan approval is somewhat accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "g = sb.FacetGrid(data = loan_df, col = 'LoanStatus', hue = 'ProsperRating', hue_order = ['AA', 'A', 'B', 'C', 'D', 'E', 'HR'],aspect = 1.5,palette =  'viridis_r' , size = 5, col_wrap = 2)\n",
    "g.map(sb.regplot, 'LoanOriginalAmount', 'LenderYield', fit_reg = False, x_jitter = 0.04)\n",
    "plt.legend(bbox_to_anchor=[1.15,0.7], title= 'Risk rating');\n",
    "\n",
    "{\n",
    "    \"tags\": [\n",
    "        \"to_remove\"\n",
    "    ],\n",
    "    \"slideshow\": {\n",
    "        \"slide_type\": \"Sub-Slide\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Defaulted category only has loans of 25,000 dollars and below. \n",
    "\n",
    ">There are not many loans above 25,000 dollars. This could be because borrowers with a riskier rating got approved for lower loan amounts, which makes sense considering the fact that they may be under heavy financial pressure. \n",
    "\n",
    ">In the Current category,there are much more loans being taken past the 25,000 dollar mark and even past the 30,000 dollars mark and veering towards the maximum of 35000 dollars.\n",
    "\n",
    ">It is also observed that high risk loans  have a higher lender yield. This is understandable as borrowers with poor credit rating will have higher APR which return higher yields. \n",
    "\n",
    ">The plot also shows that many defaulted loans are in the high risk category. This proves that the prosper rating system for loan approval is somewhat accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Generate Slideshow\n",
    "Once you're ready to generate your slideshow, use the `jupyter nbconvert` command to generate the HTML slide show.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Use this command if you are running this file in local\n",
    "!jupyter nbconvert <Part_II_slide_deck_template>.ipynb --to slides --post serve --no-input --no-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!jupyter nbconvert Part_II_slide_deck_template.ipynb --to slides --post serve --template output-toggle.tpl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "> In the classroom workspace, the generated HTML slideshow will be placed in the home folder. \n",
    "\n",
    "> In local machines, the command above should open a tab in your web browser where you can scroll through your presentation. Sub-slides can be accessed by pressing 'down' when viewing its parent slide. Make sure you remove all of the quote-formatted guide notes like this one before you finish your presentation! At last, you can stop the Kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Submission\n",
    "If you are using classroom workspace, you can choose from the following two ways of submission:\n",
    "\n",
    "1. **Submit from the workspace**. Make sure you have removed the example project from the /home/workspace directory. You must submit the following files:\n",
    "   - Part_I_notebook.ipynb\n",
    "   - Part_I_notebook.html or pdf\n",
    "   - Part_II_notebook.ipynb\n",
    "   - Part_I_slides.html\n",
    "   - README.md\n",
    "   - dataset (optional)\n",
    "\n",
    "\n",
    "2. **Submit a zip file on the last page of this project lesson**. In this case, open the Jupyter terminal and run the command below to generate a ZIP file. \n",
    "```bash\n",
    "zip -r my_project.zip .\n",
    "```\n",
    "The command abobve will ZIP every file present in your /home/workspace directory. Next, you can download the zip to your local, and follow the instructions on the last page of this project lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
